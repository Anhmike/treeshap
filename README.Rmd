---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)

set.seed(21)
```

# treeshap

<!-- badges: start -->
<!-- badges: end -->

In the era of complicated classifiers conquering their market, sometimes even the authors of algorithms do not know the exact manner of building a tree ensemble model. The difficulties in models' structures are one of the reasons why most users use them simply like black-boxes. But, how can they know whether the prediction made by the model is reasonable? `treeshap` is an efficient answer for this question. Due to implementing an optimised alghoritm for tree ensemble models, it calculates the SHAP values in polynomial (instead of exponential) time. This metric is the only possible way to measure the influence of every feature regardless of the permutation of features. Moreover, `treeshap` package shares a bunch of functions to unify the structure of a model. Currently it supports models produced with `XGBoost`, `LightGBM`, `GBM` and `Catboost`.

## Installation

You can install the released version of treeshap using package `devtools` with:

``` r
devtools::install_github('https://github.com/pawel99k/treeshap')
```

## Example

First of all, let's focus on an example how to represent a `xgboost` model as a unified data frame:
```{r unifier-example}
library(treeshap)
library(xgboost)
data <- fifa20$data[colnames(fifa20$data) != 'work_rate']
target <- fifa20$target
param <- list(objective = "reg:squarederror", max_depth = 6)
xgb_model <- xgboost::xgboost(as.matrix(data), params = param, label = target, nrounds = 200, verbose = 0)
unified <- xgboost.unify(xgb_model)
unified
```
Having the data frame of unified structure, it is a piece of cake to produce shap values of a prediction for a specific observation.
The `treeshap()` function requires passing two data frames: one representing an ensemble model and one with the observations about which we want to get the explanation. Obviously, the latter one should contain the same columns as data used during building the model.
```{r treeshap-example}
treeshap_values <- treeshap(unified,  fifa20$data[700:800, colnames(fifa20$data) != 'work_rate'])
head(treeshap_values[,1:6])
```

## How fast does it work?

Complexity of TreeSHAP is `O(TLD^2)`, where `T` is number of trees, `L` is number of leaves in a tree and `D` is depth of a tree.

Our implementation works in speed comparable to original Lundberg's Python package `shap` implementation using C and Python.

In the following example our TreeSHAP implementation explains 300 observations on a model consisting of 200 trees of max depth = 6 in less than 2 seconds. 

```{r benchmark}
microbenchmark::microbenchmark(
  treeshap = treeshap(unified,  fifa20$data[1:300, colnames(fifa20$data) != 'work_rate']),
  times = 5
)
```


## How to use the unifying functions?

Even though the data frames produced by the functions from `.unify()` family (`xgboost.unify()`, `lightgbm.unify()`, `gbm.unify()`, `catboost.unify()`) are identical when it comes to the structure, due to different possibilities of saving and representing the trees among the packages, the usage of functions is slightly different. As an argument, first three listed functions take an object of appropriate model. The latter one, `catboost.unify()` requires a transformed dataset used for training the model - an object of class `catboost.Pool`. Here is a short example representing usage of two functions:

#### 1. GBM
An argument of `gbm.unify()` should be of `gbm` class - a gradient boosting model.
```{r gbm}
library(gbm)
library(treeshap)
x <- fifa20$data[colnames(fifa20$data) != 'work_rate']
x['value_eur'] <- fifa20$target
gbm_model <- gbm::gbm(
  formula = value_eur ~ .,
  data = x,
  distribution = "laplace",
  n.trees = 200,
  cv.folds = 2,
  interaction.depth = 2
)
head(gbm.unify(gbm_model))
```

#### 2. Catboost

For representing correct names of features that are regarding during splitting observations into sets, `catboost.unify()` requires passing two arguments. Some values (Quality/Score) are unavailable for internal nodes in the data frame created on catboost model:

```{r catboost}
library(treeshap)
library(catboost)
data <- fifa20$data[colnames(fifa20$data) != 'work_rate']
label <- fifa20$target
dt.pool <- catboost::catboost.load_pool(data = as.data.frame(lapply(data, as.numeric)), label = label)
cat_model <- catboost::catboost.train(
            dt.pool,
            params = list(loss_function = 'RMSE', iterations = 100, metric_period = 10,
                          logging_level = 'Silent', allow_writing_files = FALSE))
head(catboost.unify(cat_model, dt.pool))
```



## References

* Scott M. Lundberg, Gabriel G. Erion, Su-In Lee, "Consistent Individualized Feature Attribution for Tree Ensembles", University of Washington
